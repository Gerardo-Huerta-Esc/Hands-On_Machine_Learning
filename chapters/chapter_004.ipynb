{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras para este capítulo:\n",
    "tweaks - ajustes\n",
    "several - varias/varios\n",
    "still - aún\n",
    "switching  - transpuesta\n",
    "setting - configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un folder para guardar las imágenes generadas (si es que no existe ya), y definimos la función save_fig() \n",
    "# que se utilizará para guardar las imágenes\n",
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"training_linear_models\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiaremos la regresión lineal. Uno de los algoritmos más simples. Se abordará de dos métodos de entrenamientos muy distintos:\n",
    "- Utilizando una ecuación cerrada (closet-form equation) la cual calcula los parámetros del modelo que más se ajustan a los datos de entrenamiento (es decir, los parámetros del modelo que minimizan la función de costo sobre el conjunto de entrenamiento)\n",
    "- Usando el Descenso del Gradiente (Gradient Descent \"GD\") el cual ajusta gradualmente los parámetros del modelo para minimizar la función de costo sobre el conjunto de entrenamiento. Eventualmente este método converge al mismo conjunto de parámetros que el primer método.\n",
    "\n",
    "Después revisaremos la Regresión Polinómica, un modelo más complejo que puede abordar datos no lineales. Ya que este modelo tiene más parámetros que el modelo de Regresión Lineal, es más propenso a sobre ajustarse a los datos de entrenamiento. Por lo que estaremos aprendiendo a detectar si este es el caso o no, usando curvas de aprendizaje (learning curves), y después veremos varias técnicas de regularización que pueden reducir el riezgo de sobre ajuste en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera general, un modelo lineal hace una predicción calculando la suma ponderada de las características de entreda, mas una constante llamada término de sesgo (o término de intersección)\n",
    "\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$$\n",
    "\n",
    "- $\\hat{y}$ es el valor predicho.\n",
    "\n",
    "- $n$ es el número de características.\n",
    "\n",
    "- $x_i$ es el valor de la característica $i^{th}$.\n",
    "\n",
    "- $\\theta_j$ es el parémetro del modelo  $j^{th}$ (incluido el término de sesgo $\\theta_0$ y la característica de pesos $\\theta_1 + \\theta_2 + ,..., + \\theta_n$)\n",
    "\n",
    "Esto puede escribirse de una forma más concisa usando la notación vectorial:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{y} = h_{\\theta}(x) = \\mathbf{\\theta} \\cdot \\mathbf{x}\n",
    "$$\n",
    "(no se aprecia bien, pero $\\theta$ está en negrita porque es un vector, igual que $\\mathbf{x}$)\n",
    "\n",
    "En esta ecuación:\n",
    "- $\\mathbf{\\theta}$ es el vector de parámetros del modelo, que contiene el término de sesgo $\\theta_0$ y los pesos de las características $\\theta_1$ a $\\theta_n$.\n",
    "- $\\mathbf{x}$ es el vector de características de la instancia, que contiene $x_0$ a $x_n$, con $x_0$ siempre igual a 1.\n",
    "- $\\mathbf{\\theta} \\cdot \\mathbf{x}$ es el producto punto de los vectores $\\theta$ y $\\mathbf{x}$, que por supuesto es igual a $\\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n$.\n",
    "- $h_{\\mathbf{\\theta}}$ es la función de hipótesis, usando los parámetros del modelo $\\theta$.\n",
    "\n",
    "En machine learning, una función de hipótesis es una función matemática que representa el modelo que estás utilizando para hacer predicciones, es fundamental porque dedine cómo el modelo transforma las entradas en predicciones. En otras palabras, la función de hipótesis $ h_{\\theta}(x)$ utiliza los parámetros $\\theta$ y los valores de las características $\\mathbf{x}$ para calcular la predicción de la salida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, ese es el modelo de Regresión Lineal, pero ¿cómo lo entrenamos? Bueno, recordemos que entrenar un modelo significa ajustar sus parámetros para que el modelo se ajuste mejor al conjunto de entrenamiento. Para este propósito, primero necesitamos una medida de qué tan bien (o mal) el modelo se ajusta a los datos de entrenamiento. En el Capítulo 2 vimos que la medida de rendimiento más común de un modelo de regresión es el Error Cuadrático Medio de la raíz $^{\\textbf{[1]}}$ (Root Mean Square Error: RMSE). Por lo tanto, para entrenar un modelo de Regresión Lineal, necesitamos encontrar el valor de $\\theta$ que minimice el RMSE. En la práctica, es más sencillo minimizar el error cuadrático medio (MSE) que el RMSE, y conduce al mismo resultado (porque el valor que minimiza una función también minimiza su raíz cuadrada).\n",
    "\n",
    "El MSE de una hipótesis de Regresión Lineal $ h_\\theta(x) $ en un conjunto de entrenamiento $\\mathbf{X}$ se calcula usando la siguiente ecuación.\n",
    "\n",
    "$$\n",
    "\\text{MSE}(X, h_{\\theta}) = \\frac{1}{m} \\sum_{i=1}^{m} (\\theta^\\top x^{(i)} - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "\n",
    "### La Ecuación Normal\n",
    "Para encontrar el valor de $ \\theta $ que minimiza la función de costo, existe una solución de forma cerrada, en otras palabras, una ecuación matemática que da el resultado directamente. Esto se llama la Ecuación Normal:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = (X^\\top X)^{-1} X^\\top y\n",
    "$$\n",
    "\n",
    "En esta ecuación:\n",
    "- $ \\hat{\\theta} $ es el valor de $ \\theta $ que minimiza la función de costo.\n",
    "- $ y $ es el vector de valores objetivo que contiene $ y_1 $ a $ y_n $.\n",
    "\n",
    "Generemos algunos datos con apariencia lineal para probar esta ecuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{[1]}$ \n",
    "\n",
    "En machine learning, el Root Mean Square Error (RMSE) se traduce al español como Error Cuadrático Medio de la Raíz. Es una métrica que se utiliza comúnmente para evaluar la precisión de un modelo de regresión. Se calcula como la raíz cuadrada de la media de los errores al cuadrado entre los valores predichos por el modelo y los valores reales del conjunto de datos.\n",
    "\n",
    "En términos matemáticos, el RMSE se define como:\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2} $$\n",
    "\n",
    "donde:\n",
    "- $ m $ es el número de ejemplos en el conjunto de datos.\n",
    "- $ y_i $ son los valores reales del objetivo para el i-ésimo ejemplo.\n",
    "- $ \\hat{y}_i $ son los valores predichos por el modelo para el i-ésimo ejemplo.\n",
    "\n",
    "\n",
    "\n",
    "La ecuación del Mean Squared Error (MSE) para evaluar un modelo de regresión es simplemente:\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "\n",
    "El MSE calcula el promedio de los cuadrados de los errores entre las predicciones del modelo ($ \\hat{y}_i $) y los valores reales ($ y_i $). Es una medida de la calidad de las predicciones del modelo, donde valores más bajos indican un mejor ajuste del modelo a los datos observados.\n",
    "\n",
    "\n",
    "\n",
    "La principal diferencia entre RMSE y Mean Squared Error (MSE) radica en la interpretación de la métrica resultante:\n",
    "- **MSE**: Es simplemente la media de los errores al cuadrado entre los valores predichos y los valores reales, sin la raíz cuadrada. Por lo tanto, MSE es más sensible a valores atípicos (outliers) en los datos, ya que los errores más grandes contribuyen de manera proporcionalmente mayor a la métrica.\n",
    "- **RMSE**: Al tomar la raíz cuadrada del MSE, el RMSE proporciona una medida de error que está en la misma unidad que la variable objetivo original. Esto hace que sea más interpretable, ya que representa el error promedio en la misma escala que los datos originales, además penaliza de manera más significativa los errores grandes en comparación con el MSE.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
